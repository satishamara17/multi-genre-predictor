{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2668b10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, TensorDataset\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "import sklearn\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report, hamming_loss,confusion_matrix\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torchinfo import summary\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4e918b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16MultiLabel(nn.Module):\n",
    "    def __init__(self, num_classes=28):\n",
    "        super(VGG16MultiLabel, self).__init__()\n",
    "        vgg = models.vgg16(weights=models.VGG16_Weights.DEFAULT)\n",
    "        for param in vgg.features.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.features = vgg.features\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512 * 6 * 4, 2056),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2056, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.6),\n",
    "            nn.Linear(1024, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43ba5cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preloading to GPU: 100%|██████████| 7252/7252 [01:46<00:00, 68.02it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "class MoviePosterDataset(Dataset):\n",
    "    def __init__(self, csv_file, image_dir, transform=None, genre_to_idx=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # Convert stringified lists to actual lists\n",
    "        self.data['genres'] = self.data['genres'].apply(ast.literal_eval)\n",
    "\n",
    "        # Build genre index mapping if not provided\n",
    "        self.all_genres = sorted(set(g for genre_list in self.data['genres'] for g in genre_list))\n",
    "        self.genre_to_idx = genre_to_idx or {genre: idx for idx, genre in enumerate(self.all_genres)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def get_genre_idx(self):\n",
    "        return self.genre_to_idx\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        movie_id = row['movie_id']\n",
    "        genres = row['genres']\n",
    "\n",
    "        # Multi-hot encode the genres\n",
    "        label = torch.zeros(len(self.genre_to_idx))\n",
    "        for genre in genres:\n",
    "            if genre in self.genre_to_idx:\n",
    "                label[self.genre_to_idx[genre]] = 1.0\n",
    "\n",
    "        # Load image\n",
    "        img_path = os.path.join(self.image_dir, f\"{movie_id}.jpg\")\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((200,150)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
    "])\n",
    "\n",
    "csv_file = \"movies_with_posters.csv\"\n",
    "image_dir = \"C:/Users/satis/Downloads/datasets/posters\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"using \",device)\n",
    "dataset = MoviePosterDataset(csv_file, image_dir, transform)\n",
    "genre_to_idx = dataset.get_genre_idx()\n",
    "\n",
    "total_size = len(dataset)\n",
    "indices = list(range(total_size))\n",
    "train_idx, temp_idx = train_test_split(indices, test_size=0.3, random_state=42)\n",
    "\n",
    "test_set = Subset(dataset, temp_idx)\n",
    "\n",
    "def preload_to_gpu(subset, device):\n",
    "    imgs, labels = [], []\n",
    "    for img, label in tqdm(subset, desc=\"Preloading to GPU\"):\n",
    "        imgs.append(img.unsqueeze(0))\n",
    "        labels.append(label.unsqueeze(0))\n",
    "    imgs = torch.cat(imgs).to(device)\n",
    "    labels = torch.cat(labels).to(device)\n",
    "    print(imgs.device) \n",
    "    print(labels.device)\n",
    "    return TensorDataset(imgs, labels)\n",
    "\n",
    "test_tensor_dataset = preload_to_gpu(test_set, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3c493fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "VGG16MultiLabel                          [1, 9]                    --\n",
      "├─Sequential: 1-1                        [1, 512, 6, 4]            --\n",
      "│    └─Conv2d: 2-1                       [1, 64, 200, 150]         (1,792)\n",
      "│    └─ReLU: 2-2                         [1, 64, 200, 150]         --\n",
      "│    └─Conv2d: 2-3                       [1, 64, 200, 150]         (36,928)\n",
      "│    └─ReLU: 2-4                         [1, 64, 200, 150]         --\n",
      "│    └─MaxPool2d: 2-5                    [1, 64, 100, 75]          --\n",
      "│    └─Conv2d: 2-6                       [1, 128, 100, 75]         (73,856)\n",
      "│    └─ReLU: 2-7                         [1, 128, 100, 75]         --\n",
      "│    └─Conv2d: 2-8                       [1, 128, 100, 75]         (147,584)\n",
      "│    └─ReLU: 2-9                         [1, 128, 100, 75]         --\n",
      "│    └─MaxPool2d: 2-10                   [1, 128, 50, 37]          --\n",
      "│    └─Conv2d: 2-11                      [1, 256, 50, 37]          (295,168)\n",
      "│    └─ReLU: 2-12                        [1, 256, 50, 37]          --\n",
      "│    └─Conv2d: 2-13                      [1, 256, 50, 37]          (590,080)\n",
      "│    └─ReLU: 2-14                        [1, 256, 50, 37]          --\n",
      "│    └─Conv2d: 2-15                      [1, 256, 50, 37]          (590,080)\n",
      "│    └─ReLU: 2-16                        [1, 256, 50, 37]          --\n",
      "│    └─MaxPool2d: 2-17                   [1, 256, 25, 18]          --\n",
      "│    └─Conv2d: 2-18                      [1, 512, 25, 18]          (1,180,160)\n",
      "│    └─ReLU: 2-19                        [1, 512, 25, 18]          --\n",
      "│    └─Conv2d: 2-20                      [1, 512, 25, 18]          (2,359,808)\n",
      "│    └─ReLU: 2-21                        [1, 512, 25, 18]          --\n",
      "│    └─Conv2d: 2-22                      [1, 512, 25, 18]          (2,359,808)\n",
      "│    └─ReLU: 2-23                        [1, 512, 25, 18]          --\n",
      "│    └─MaxPool2d: 2-24                   [1, 512, 12, 9]           --\n",
      "│    └─Conv2d: 2-25                      [1, 512, 12, 9]           (2,359,808)\n",
      "│    └─ReLU: 2-26                        [1, 512, 12, 9]           --\n",
      "│    └─Conv2d: 2-27                      [1, 512, 12, 9]           (2,359,808)\n",
      "│    └─ReLU: 2-28                        [1, 512, 12, 9]           --\n",
      "│    └─Conv2d: 2-29                      [1, 512, 12, 9]           (2,359,808)\n",
      "│    └─ReLU: 2-30                        [1, 512, 12, 9]           --\n",
      "│    └─MaxPool2d: 2-31                   [1, 512, 6, 4]            --\n",
      "├─Sequential: 1-2                        [1, 9]                    --\n",
      "│    └─Flatten: 2-32                     [1, 12288]                --\n",
      "│    └─Linear: 2-33                      [1, 2056]                 25,266,184\n",
      "│    └─ReLU: 2-34                        [1, 2056]                 --\n",
      "│    └─Linear: 2-35                      [1, 1024]                 2,106,368\n",
      "│    └─ReLU: 2-36                        [1, 1024]                 --\n",
      "│    └─Dropout: 2-37                     [1, 1024]                 --\n",
      "│    └─Linear: 2-38                      [1, 9]                    9,225\n",
      "==========================================================================================\n",
      "Total params: 42,096,465\n",
      "Trainable params: 27,381,777\n",
      "Non-trainable params: 14,714,688\n",
      "Total mult-adds (G): 9.00\n",
      "==========================================================================================\n",
      "Input size (MB): 0.36\n",
      "Forward/backward pass size (MB): 64.33\n",
      "Params size (MB): 168.39\n",
      "Estimated Total Size (MB): 233.07\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VGG16MultiLabel(9)\n",
    "print(summary(model, input_size=(1, 3, 200, 150)))\n",
    "model.load_state_dict(torch.load('vgg16_genre_model.pth', map_location=torch.device('cpu'), weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee39b176",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_tensor_dataset, batch_size=16, shuffle=False)\n",
    "model.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        preds = (probs > 0.4).int()\n",
    "\n",
    "        all_preds.append(preds.cpu())\n",
    "        all_targets.append(labels.cpu())\n",
    "\n",
    "y_true = torch.cat(all_targets).numpy()\n",
    "y_pred = torch.cat(all_preds).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80454f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Action       0.37      0.35      0.36      1156\n",
      "   Adventure       0.36      0.30      0.33      1112\n",
      "      Comedy       0.48      0.53      0.50      1218\n",
      "       Crime       0.28      0.33      0.30      1220\n",
      "       Drama       0.48      0.65      0.55      1214\n",
      "      Horror       0.51      0.40      0.45      1235\n",
      "     Romance       0.37      0.37      0.37      1230\n",
      "      Sci-Fi       0.42      0.41      0.42      1170\n",
      "    Thriller       0.32      0.26      0.29      1197\n",
      "\n",
      "   micro avg       0.40      0.40      0.40     10752\n",
      "   macro avg       0.40      0.40      0.40     10752\n",
      "weighted avg       0.40      0.40      0.40     10752\n",
      " samples avg       0.41      0.43      0.39     10752\n",
      "\n",
      "Hamming Loss: 0.1973\n"
     ]
    }
   ],
   "source": [
    "label_names = [i for i in genre_to_idx.keys()]\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=label_names, zero_division=0))\n",
    "\n",
    "loss = hamming_loss(y_true, y_pred)\n",
    "print(f\"Hamming Loss: {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f9c443",
   "metadata": {},
   "source": [
    "### Give a random poster as input and get the genres it belongs to.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0829005d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((200,150)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02765b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "posters/tt0002797.jpg\n"
     ]
    }
   ],
   "source": [
    "# select a random index from the posters folder or input the image you want to classify.\n",
    "model.to('cpu')\n",
    "imdb_id = \"tt0002797\"\n",
    "img_path = f\"posters/{imdb_id}.jpg\"\n",
    "print(img_path)\n",
    "image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "input_tensor = transform(image).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca4e7793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class index: 2\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(input_tensor)\n",
    "    predicted_class = outputs.argmax(dim=1).item()\n",
    "\n",
    "print(f'Predicted class index: {predicted_class}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40d42cc",
   "metadata": {},
   "source": [
    "{'Action': 0,\n",
    " 'Adventure': 1,\n",
    " 'Comedy': 2,\n",
    " 'Crime': 3,\n",
    " 'Drama': 4,\n",
    " 'Horror': 5,\n",
    " 'Romance': 6,\n",
    " 'Sci-Fi': 7,\n",
    " 'Thriller': 8}  \\\\\n",
    "\n",
    " Above are the indices of the respective genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b252a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Comedy']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"movies_with_posters.csv\")\n",
    "genre_row = df.loc[df['movie_id'] == imdb_id, 'genres']\n",
    "print(genre_row.values[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
